{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Neural Networks with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Prepare MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "transform = transforms.Compose([\n",
    "#           Data Augmentation\n",
    "#           transforms.RandomRotation(15)\n",
    "#           transforms.CenterCrop(28),\n",
    "#           transforms.Lambda(lambda x: x.rotate(15)),\n",
    "    \n",
    "#           Data Nomalization\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "# Normalize a tensor image with mean and standard deviation.\n",
    "# Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels,\n",
    "# this transform will normalize each channel of the input torch.\n",
    "# *Tensor i.e. input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "            ])\n",
    "\n",
    "\n",
    "train_data = dsets.MNIST(root='data/',\n",
    "                         train=True,\n",
    "                         transform=transform,\n",
    "                         download=True)\n",
    "\n",
    "test_data = dsets.MNIST(root='data/',\n",
    "                        train=False,\n",
    "                        transform=transform,\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size(), test_data.data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Make Batch Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "train_loader  = DataLoader(dataset=train_data,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True,\n",
    "                           num_workers=1)\n",
    "\n",
    "test_loader  = DataLoader(dataset=test_data,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True,\n",
    "                           num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    #Dropout\n",
    "    nn.Dropout(0.35),\n",
    "    \n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    nn.Dropout(0.35),\n",
    "    \n",
    "    torch.nn.Linear(256, 64),\n",
    "    #Batch Nomalization\n",
    "    nn.BatchNorm1d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Initialization\n",
    "\n",
    "for m in model.modules() :\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # init.xavier_normal(m.weight.data)\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Momentum & Weight Regularization(L2)\n",
    "# optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model() :\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader :\n",
    "\n",
    "        outputs = model(images.view(-1, 28 * 28))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of test images: %f %%' % (75 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './model/'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], lter [300/1200], Loss: 0.4940\n",
      "Accuracy of test images: 69.517500 %\n",
      "./model/model_1_300.pth\n",
      "Epoch [1/10], lter [600/1200], Loss: 0.4106\n",
      "Accuracy of test images: 70.485000 %\n",
      "./model/model_1_600.pth\n",
      "Epoch [1/10], lter [900/1200], Loss: 0.3258\n",
      "Accuracy of test images: 71.212500 %\n",
      "./model/model_1_900.pth\n",
      "Epoch [1/10], lter [1200/1200], Loss: 0.1522\n",
      "Accuracy of test images: 70.807500 %\n",
      "./model/model_1_1200.pth\n",
      "Epoch [2/10], lter [300/1200], Loss: 0.2277\n",
      "Accuracy of test images: 71.137500 %\n",
      "./model/model_2_300.pth\n",
      "Epoch [2/10], lter [600/1200], Loss: 0.1946\n",
      "Accuracy of test images: 71.587500 %\n",
      "./model/model_2_600.pth\n",
      "Epoch [2/10], lter [900/1200], Loss: 0.0489\n",
      "Accuracy of test images: 71.542500 %\n",
      "./model/model_2_900.pth\n",
      "Epoch [2/10], lter [1200/1200], Loss: 0.1766\n",
      "Accuracy of test images: 72.097500 %\n",
      "./model/model_2_1200.pth\n",
      "Epoch [3/10], lter [300/1200], Loss: 0.2022\n",
      "Accuracy of test images: 71.880000 %\n",
      "./model/model_3_300.pth\n",
      "Epoch [3/10], lter [600/1200], Loss: 0.1050\n",
      "Accuracy of test images: 72.172500 %\n",
      "./model/model_3_600.pth\n",
      "Epoch [3/10], lter [900/1200], Loss: 0.1825\n",
      "Accuracy of test images: 72.150000 %\n",
      "./model/model_3_900.pth\n",
      "Epoch [3/10], lter [1200/1200], Loss: 0.1071\n",
      "Accuracy of test images: 72.270000 %\n",
      "./model/model_3_1200.pth\n",
      "Epoch [4/10], lter [300/1200], Loss: 0.0734\n",
      "Accuracy of test images: 72.307500 %\n",
      "./model/model_4_300.pth\n",
      "Epoch [4/10], lter [600/1200], Loss: 0.1650\n",
      "Accuracy of test images: 72.157500 %\n",
      "./model/model_4_600.pth\n",
      "Epoch [4/10], lter [900/1200], Loss: 0.3855\n",
      "Accuracy of test images: 72.457500 %\n",
      "./model/model_4_900.pth\n",
      "Epoch [4/10], lter [1200/1200], Loss: 0.0430\n",
      "Accuracy of test images: 72.667500 %\n",
      "./model/model_4_1200.pth\n",
      "Epoch [5/10], lter [300/1200], Loss: 0.2118\n",
      "Accuracy of test images: 72.307500 %\n",
      "./model/model_5_300.pth\n",
      "Epoch [5/10], lter [600/1200], Loss: 0.1685\n",
      "Accuracy of test images: 72.540000 %\n",
      "./model/model_5_600.pth\n",
      "Epoch [5/10], lter [900/1200], Loss: 0.1433\n",
      "Accuracy of test images: 72.840000 %\n",
      "./model/model_5_900.pth\n",
      "Epoch [5/10], lter [1200/1200], Loss: 0.1999\n",
      "Accuracy of test images: 72.787500 %\n",
      "./model/model_5_1200.pth\n",
      "Epoch [6/10], lter [300/1200], Loss: 0.1464\n",
      "Accuracy of test images: 72.660000 %\n",
      "./model/model_6_300.pth\n",
      "Epoch [6/10], lter [600/1200], Loss: 0.2055\n",
      "Accuracy of test images: 72.780000 %\n",
      "./model/model_6_600.pth\n",
      "Epoch [6/10], lter [900/1200], Loss: 0.1029\n",
      "Accuracy of test images: 72.637500 %\n",
      "./model/model_6_900.pth\n",
      "Epoch [6/10], lter [1200/1200], Loss: 0.0353\n",
      "Accuracy of test images: 72.652500 %\n",
      "./model/model_6_1200.pth\n",
      "Epoch [7/10], lter [300/1200], Loss: 0.1155\n",
      "Accuracy of test images: 72.937500 %\n",
      "./model/model_7_300.pth\n",
      "Epoch [7/10], lter [600/1200], Loss: 0.4305\n",
      "Accuracy of test images: 73.027500 %\n",
      "./model/model_7_600.pth\n",
      "Epoch [7/10], lter [900/1200], Loss: 0.1543\n",
      "Accuracy of test images: 72.772500 %\n",
      "./model/model_7_900.pth\n",
      "Epoch [7/10], lter [1200/1200], Loss: 0.1970\n",
      "Accuracy of test images: 72.742500 %\n",
      "./model/model_7_1200.pth\n",
      "Epoch [8/10], lter [300/1200], Loss: 0.0136\n",
      "Accuracy of test images: 73.095000 %\n",
      "./model/model_8_300.pth\n",
      "Epoch [8/10], lter [600/1200], Loss: 0.1552\n",
      "Accuracy of test images: 72.855000 %\n",
      "./model/model_8_600.pth\n",
      "Epoch [8/10], lter [900/1200], Loss: 0.1070\n",
      "Accuracy of test images: 72.832500 %\n",
      "./model/model_8_900.pth\n",
      "Epoch [8/10], lter [1200/1200], Loss: 0.1239\n",
      "Accuracy of test images: 73.012500 %\n",
      "./model/model_8_1200.pth\n",
      "Epoch [9/10], lter [300/1200], Loss: 0.0385\n",
      "Accuracy of test images: 73.110000 %\n",
      "./model/model_9_300.pth\n",
      "Epoch [9/10], lter [600/1200], Loss: 0.0418\n",
      "Accuracy of test images: 73.117500 %\n",
      "./model/model_9_600.pth\n",
      "Epoch [9/10], lter [900/1200], Loss: 0.4001\n",
      "Accuracy of test images: 73.110000 %\n",
      "./model/model_9_900.pth\n",
      "Epoch [9/10], lter [1200/1200], Loss: 0.0300\n",
      "Accuracy of test images: 73.132500 %\n",
      "./model/model_9_1200.pth\n",
      "Epoch [10/10], lter [300/1200], Loss: 0.1076\n",
      "Accuracy of test images: 73.095000 %\n",
      "./model/model_10_300.pth\n",
      "Epoch [10/10], lter [600/1200], Loss: 0.1524\n",
      "Accuracy of test images: 73.087500 %\n",
      "./model/model_10_600.pth\n",
      "Epoch [10/10], lter [900/1200], Loss: 0.2699\n",
      "Accuracy of test images: 73.275000 %\n",
      "./model/model_10_900.pth\n",
      "Epoch [10/10], lter [1200/1200], Loss: 0.1012\n",
      "Accuracy of test images: 73.290000 %\n",
      "./model/model_10_1200.pth\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_batch = len(train_data) // batch_size\n",
    "    \n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        \n",
    "        X = batch_images.view(-1, 28 * 28)\n",
    "        Y = batch_labels\n",
    "        \n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 300 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n",
    "            \n",
    "            # Test Model\n",
    "            test_model()\n",
    "            \n",
    "            # Save Model\n",
    "            model_path = save_path + 'model_' + str(epoch+1) + '_' + str(i+1) + '.pth'\n",
    "            print(model_path)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            model.train()\n",
    "    \n",
    "print(\"Learning Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    #Dropout\n",
    "    nn.Dropout(0.5),\n",
    "    \n",
    "    torch.nn.Linear(512, 350),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Linear(350, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Linear(256, 64),\n",
    "    #Batch Nomalization\n",
    "    nn.BatchNorm1d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 97.720000 %\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model/model_10_1200.pth'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_data:\n",
    "    \n",
    "    images  = images.view(-1, 28 * 28)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += 1\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of test images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
